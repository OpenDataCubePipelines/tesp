#!/usr/bin/env python

"""
PBS submission scripts.
"""

import os
import re
import json
import logging
from os.path import join as pjoin, dirname, exists
import subprocess
import uuid
import click

from wagl.tiling import scatter


PBS_RESOURCES = ("""#!/bin/bash
#PBS -P {project}
#PBS -W umask=017
#PBS -q {queue}
#PBS -l walltime={walltime},mem={memory}GB,ncpus={ncpus},jobfs={jobfs}GB,other=pernodejobfs
#PBS -l wd
#PBS -me
{email}
""")

NODE_TEMPLATE = ("""{pbs_resources}
source {env}

{daemon}

luigi --module tesp.workflow ARDP --level1-list {scene_list} --workdir {outdir} --pkgdir {pkgdir} --workers {workers} --parallel-scheduling
""")


FMT1 = 'batchid-{batchid}'
FMT2 = 'jobid-{jobid}'
FMT3 = 'level1-scenes-{jobid}.txt'
FMT4 = 'jobid-{jobid}.bash'
DAEMON_FMT = 'luigid --background --logdir {}'


# pylint: disable=too-many-arguments
def _submit_multiple(scattered, env, batch_logdir, batch_outdir, pkgdir,
                     workers, pbs_resources, test):
    """Submit multiple PBS formatted jobs."""

    nci_job_ids = []

    # setup and submit each block of scenes for processing
    for block in scattered:
        jobid = uuid.uuid4().hex[0:6]
        jobdir = pjoin(batch_logdir, FMT2.format(jobid=jobid))
        job_outdir = pjoin(batch_outdir, FMT2.format(jobid=jobid))

        if not exists(jobdir):
            os.makedirs(jobdir)

        if not exists(job_outdir):
            os.makedirs(job_outdir)

        # write level1 data listing
        out_fname = pjoin(jobdir, FMT3.format(jobid=jobid))
        with open(out_fname, 'w') as src:
            src.writelines(block)

        pbs = NODE_TEMPLATE.format(pbs_resources=pbs_resources, env=env,
                                   daemon=DAEMON_FMT.format(jobdir),
                                   scene_list=out_fname, outdir=job_outdir,
                                   pkgdir=pkgdir, workers=workers)

        # write pbs script
        out_fname = pjoin(jobdir, FMT4.format(jobid=jobid))
        with open(out_fname, 'w') as src:
            src.write(pbs)

        if test:
            click.echo("Mocking... Submitting Job: {} ...Mocking".format(jobid))
            click.echo("qsub {}".format(out_fname))
            continue

        os.chdir(dirname(out_fname))
        click.echo("Submitting Job: {}".format(jobid))
        try:
            raw_output = subprocess.check_output(['qsub', out_fname])
        except subprocess.CalledProcessError as exc:
            logging.error('qsub failed with exit code %s', str(exc.returncode))
            logging.error(exc.output)
            raise

        if hasattr(raw_output, 'decode'):
            matches = re.match('^(?P<nci_job_id>\d{7,}.r-man2)$', raw_output.decode('utf-8'))
            if matches:
                nci_job_ids.append(matches.groupdict()['nci_job_id'])

    # return a list of the nci job ids
    return nci_job_ids


@click.command()
@click.option("--level1-list", type=click.Path(exists=True, readable=True),
              help="The input level1 scene list.")
@click.option("--workdir", type=click.Path(file_okay=False, writable=True),
              help="The base output working directory.")
@click.option("--logdir", type=click.Path(file_okay=False, writable=True),
              help="The base logging and scripts output directory.")
@click.option("--pkgdir", type=click.Path(file_okay=False, writable=True),
              help="The base output packaged directory.")
@click.option("--env", type=click.Path(exists=True, readable=True),
              help="Environment script to source.")
@click.option("--workers", type=click.IntRange(1, 32), default=16,
              help="The number of workers to request per node.")
@click.option("--nodes", default=1, help="The number of nodes to request.")
@click.option("--memory", default=32,
              help="The memory in GB to request per node.")
@click.option("--jobfs", default=50,
              help="The jobfs memory in GB to request per node.")
@click.option("--project", required=True, help="Project code to run under.")
@click.option("--queue", default='normal',
              help="Queue to submit the job into, eg normal, express.")
@click.option("--walltime", default="48:00:00",
              help="Job walltime in `hh:mm:ss` format.")
@click.option("--email", default="",
              help="Notification email address.")
@click.option("--test", default=False, is_flag=True,
              help=("Test job execution (Don't submit the job to the "
                    "PBS queue)."))
# pylint: disable=too-many-arguments
def main(level1_list, workdir, logdir, pkgdir, env, workers, nodes, memory,
         jobfs, project, queue, walltime, email, test):
    """
    Equally partition a list of scenes across n nodes and submit
    n jobs into the PBS queue.
    """
    with open(level1_list, 'r') as src:
        scenes = src.readlines()

    scattered = scatter(scenes, nodes)

    batchid = uuid.uuid4().hex[0:10]
    batch_logdir = pjoin(logdir, FMT1.format(batchid=batchid))
    batch_outdir = pjoin(workdir, FMT1.format(batchid=batchid))

    # optionally set pbs email string
    pbs_resources = PBS_RESOURCES.format(project=project, queue=queue,
                                         walltime=walltime, memory=memory,
                                         ncpus=workers, jobfs=jobfs,
                                         email=('#PBS -M ' + email) if email else "")

    if test:
        click.echo("Mocking... Submitting Batch: {} ...Mocking".format(batchid))
    else:
        click.echo("Submitting Batch: {}".format(batchid))

    click.echo("Executing Batch: {}".format(batchid))
    nci_job_ids = _submit_multiple(scattered, env, batch_logdir, batch_outdir,
                                   pkgdir, workers, pbs_resources, test)

    job_details = {
        'ardpbs_batch_id': batchid,
        'nci_job_ids': nci_job_ids
    }

    # Enable the job details to be picked up by the calling process
    click.echo(json.dumps(job_details))


if __name__ == '__main__':
    main()
