#!/usr/bin/env python3

# ./s2-l1c-yaml-gen s2-l1-yaml-gen
import io
import os
import logging
import math
import tempfile
import zipfile
import sys
from xml.etree import ElementTree
from datetime import datetime, timedelta
from os.path import join, basename, isfile
from subprocess import Popen, PIPE, check_output, CalledProcessError
from pathlib import Path

import click
from click_datetime import Datetime
from dateutil.parser import parse as date_parser

DEFAULT_S2_AOI = '/g/data/v10/eoancillarydata/S2_extent/S2_aoi.csv'
DEFAULT_S2_L1C = '/g/data/fj7/Copernicus/Sentinel-2/MSI/L1C'
DEFAULT_YAML_S2_L1C = '/g/data/v10/AGDCv2/indexed_datasets/cophub/s2_v2/s2_l1c_yamls'
DEFAULT_YAML_S2_L1C = '/g/data/u46/users/dsg547/test_data/s2_yaml_gen/yaml'
DEFAULT_OOA_YAML_S2_L1C = '/g/data/u46/users/dsg547/test_data/s2_yaml_gen/ooa_yaml'

def get_tile_id(file_name: str):
    """
    Assuming a format of;
    MMM_MSIXXX_YYYYMMDDHHMMSS_Nxxyy_ROOO_Txxxxx_<Product Discriminator>
    where: Txxxxx: Tile Number field

    returns:xxxxx (the Tile Number field without the T)
    """
    split_name = file_name.split('_')
    tile_id = split_name[5][1:]
    return tile_id


def read_aoi(s2_aoi):
    # Read area of interest list
    with open(s2_aoi) as csv:
        tile_ids = {tile.strip() for tile in csv}
    return tile_ids


def _level1_dataset_iter(level1_root: Path, output_dir: Path, year_month: datetime):
    """ Yields the path to level1 archives for sentinel2

    """
    level1_dir = Path(level1_root) / year_month.strftime("%Y") / year_month.strftime("%Y-%m")
    logging.info('Find in dir ' + str(level1_dir))
    cmd = ['find', str(level1_dir)]  + ['-mindepth', '1', ] + ['-maxdepth', '2', ] + ['-name', '*.zip', ]
    in_stream = io.TextIOWrapper(Popen(cmd, stdout=PIPE).stdout, encoding='utf-8')
    logging.debug("calling %s", ' '.join(cmd))
    for level1_path in in_stream:
        yield Path(level1_path.strip())
 
@click.group()
def cli():
    pass

@cli.command('s2-l1-yaml-gen')
@click.option('--level1-root',
              type=click.Path(exists=True, readable=True),
              default=DEFAULT_S2_L1C,
              help='directory to write yamls to')
@click.option('--output-dir',
              type=click.Path(exists=True, writable=True),
              callback=lambda ctx, param, value: Path(value),
              default=DEFAULT_YAML_S2_L1C,
              help='directory to write yamls to')
@click.option('--ooa-output-dir',
              type=click.Path(exists=True, writable=True),
              callback=lambda ctx, param, value: Path(value),
              default=DEFAULT_OOA_YAML_S2_L1C,
              help='Directory to track out-of-area scenes.')
@click.option('--year-month', type=Datetime('%Y-%m'),
              default=datetime.now().strftime("%Y-%m"),
              help='Year-month to generate yamls for. i.e. 2020-09')
@click.option('--s2-aoi', default=DEFAULT_S2_AOI, type=str,
              help="List of MGRS tiles of interest.")
@click.option('--dry-run', default=False, is_flag=True)
@click.option('--log-level', default="DEBUG", type=str,   # default="WARNING"
              help="Set a log level.  e.g. WARNING INFO")
# s2_l1_yaml_gen
def s2_l1_yaml_gen(level1_root: Path, output_dir: Path, ooa_output_dir: Path,
                   s2_aoi: Path,
                   year_month: datetime, dry_run: bool, log_level: str):
    click.echo(' '.join(sys.argv))
    try:
        logging.basicConfig(level=log_level)
    except:
        logging.basicConfig(level="WARNING")
        logging.warning("Log level defaulting to warning.")
    logging.info('this is an info level test')
    logging.warning('this is a warning level test')
    print(datetime.now().strftime("%Y-%m"))

    tile_ids = read_aoi(s2_aoi)
    
    for level1_dataset in _level1_dataset_iter(level1_root, output_dir, year_month):
        # Include the parent directories of the source file; yaml files are broken up into
        # 5 degree by 5 degree geographies like level1 datasets
        # There is no reason for this breakup
        #yaml_output_dir = output_dir / '/'.join(level1_dataset.parts[-(1 + copy_parent_dir_count):-1])
        #os.makedirs(yaml_output_dir, exist_ok=True)
        print (level1_dataset)

        # This is one level1_dataset

        zip_sub_dir = level1_dataset.relative_to(level1_root)
        
        # If there is already a yaml filter it out
        
        zip_sub_dir.with_suffix('').with_suffix('.odc-metadata.yaml')
        yaml_sub_dir = zip_sub_dir.with_suffix('').with_suffix('.odc-metadata.yaml') 
        yaml = output_dir / yaml_sub_dir
        if yaml.exists():
            logging.debug('yaml exists ' + str(yaml))
            continue

        # If the s2 l1 scene is out of area
        tile_id = get_tile_id(zip_sub_dir.stem)
        print (tile_id)
        if tile_id not in tile_ids:
            logging.debug('granule %s with MGRS tile ID %s outside AOI', zip_sub_dir.stem, tile_id)
            dummy_yaml = ooa_output_dir / yaml_sub_dir
            #generate_dummy_yaml(dummy_yaml)
            continue
        else:
            logging.debug('***********  In Area  **************')
            #generate_yaml(yaml)
        #break
        continue
    
        try:
            if dry_run:
                click.echo(
                    'Processing: datasets: {}, outdir: {}, checksum: {}, start_date: {}'.format(
                        str(level1_dataset), str(yaml_output_dir), str(checksum), str(start_date)
                    )
                )
            else:
                logging.info('Processing archive: %s', str(level1_dataset))
                _process_datasets(yaml_output_dir, (level1_dataset, ), checksum, start_date)
            break
        except Exception as e:
            logging.error('Issue processing archive: %s', str(level1_dataset))
            logging.exception(e)


if __name__ == '__main__':
    cli()
